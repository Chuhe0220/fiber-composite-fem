{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4543de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy.spatial import Delaunay\n",
    "import matplotlib.tri as tri\n",
    "import copy\n",
    "#import mpi4py\n",
    "#from mpi4py import MPI\n",
    "import h5py\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c436578",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = 'utf-8'\n",
    "\n",
    "DATABASE_FIBERORIENTATION =    'FiberOrientation'\n",
    "DATABASE_FIBERVOLUMEFRACTION = 'FiberVolumeFraction'\n",
    "DATABASE_FIBERLENGTH =         'FiberLength'\n",
    "DATABASE_TEMPERATURE =         'Temperature'\n",
    "DATABASE_MODELTYPE =           'Type'\n",
    "DATABASE_MODELGEOMETRY =       'Geometry'\n",
    "\n",
    "DATABASE_MESH =                 'Mesh'\n",
    "DATABASE_CONNECTIVITY =         'Connectivity'\n",
    "DATABASE_MODEL =                'Model'\n",
    "DATABASE_POINT =                'Point'\n",
    "\n",
    "DATABASE_NAME =                 'Name'\n",
    "DATABASE_NUMBER =               'Number'\n",
    "\n",
    "\n",
    "DATABASE_MODEL_MATRIX =         'SystemMatrices'\n",
    "DATABASE_MODEL_PODMODES =       'Modes'\n",
    "DATABASE_MODEL_PODMODE =        'Mode'\n",
    "DATABASE_MODEL_VOLUMEFIELD =    'VolumeField'\n",
    "DATABASE_MODEL_VOLUMEFIELDS =   'VolumeFields'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3827cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_attrs(name, obj):\n",
    "    print(name)\n",
    "    for key, val in obj.attrs.items():\n",
    "        print(\"    {0}: {1}\".format(key, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1e55f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indent(elem, level=0):\n",
    "    i = \"\\n\" + level*\"  \"\n",
    "    if len(elem):\n",
    "        if not elem.text or not elem.text.strip():\n",
    "            elem.text = i + \"  \"\n",
    "        if not elem.tail or not elem.tail.strip():\n",
    "            elem.tail = i\n",
    "        for elem in elem:\n",
    "            indent(elem, level+1)\n",
    "        if not elem.tail or not elem.tail.strip():\n",
    "            elem.tail = i\n",
    "    else:\n",
    "        if level and (not elem.tail or not elem.tail.strip()):\n",
    "            elem.tail = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e17e6aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Address(name, name1):\n",
    "    if name ==name1:\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a9d90e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointIndicator:\n",
    "    def __init__(self,AttributeName,AttributeDimension,Tolerance):\n",
    "        self.AttributeDimension=AttributeDimension\n",
    "        self.AttributeName=np.string_(AttributeName)\n",
    "        self.Tolerance=Tolerance\n",
    "        self.TypeOfValue =type(np.zeros((AttributeDimension)))\n",
    "        self.shape = np.zeros((AttributeDimension)).shape\n",
    "\n",
    "class Mesh:\n",
    "    def __init__(self,PI,meshgeneration):\n",
    "        self.indicator=PI\n",
    "        self.generator=meshgeneration\n",
    "        self.Connectivity=None\n",
    "\n",
    "\n",
    "class Point(object):\n",
    "    def __init__(self,PI,Attributes):\n",
    "        self.indicator=PI\n",
    "        self.Attributes=Attributes\n",
    "\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self,Attributes,Data,Number=0):\n",
    "        self.Attributes=Attributes\n",
    "        self.Data=Data\n",
    "        self.Number=Number\n",
    "\n",
    "class Database(object):\n",
    "    def __init__(self,dbfile,new=False,PointIndicator=None,write=False,compression=True):\n",
    "        self.file=dbfile # filename str\n",
    "        self.PIList=PointIndicator #dict PointIndicator\n",
    "        self.write=write #bool\n",
    "        self.new=new\n",
    "        self.MeshIsAvailable=True\n",
    "        self.compression=compression\n",
    "        self.open()\n",
    "\n",
    "    def close(self):\n",
    "        self.DB.close()\n",
    "\n",
    "    def compress(self):\n",
    "        self.close()\n",
    "        print(\"compress data\")\n",
    "        os.system(\"h5repack -f GZIP=4 \"+self.file+\" \"+self.file.replace(\".h5\",\"_r.h5\"))\n",
    "        os.remove(self.file)\n",
    "        os.rename(self.file.replace(\".h5\",\"_r.h5\"),self.file)\n",
    "        self.open()\n",
    "\n",
    "    def open(self):\n",
    "        if self.new:\n",
    "            self.write=True\n",
    "\n",
    "        if self.new and self.PIList==None:\n",
    "            raise ValueError(\"can not initialize new database without point indicator\")\n",
    "\n",
    "        if not self.write:\n",
    "            try:\n",
    "                self.DB = h5py.File(self.file, 'r')\n",
    "                self.readPointIndicator()\n",
    "            except:\n",
    "                raise ValueError(\"can not open database: \"+self.file)\n",
    "        else:\n",
    "            if self.new:\n",
    "                if(os.path.isfile(self.file)):\n",
    "                    try:\n",
    "                        os.remove(self.file)\n",
    "                    except:\n",
    "                        raise ValueError(\"can not delete database: \"+self.file)\n",
    "                print(\"newFile\")\n",
    "                self.DB = h5py.File(self.file, 'w')\n",
    "                print(\"newFile2\")\n",
    "                self.writePointIndicator()\n",
    "                print(\"newFile3\")\n",
    "            else:\n",
    "                try:\n",
    "                  self.DB = h5py.File(self.file, 'r+')\n",
    "                  self.readPointIndicator()\n",
    "                except:\n",
    "                  raise ValueError(\"can not initialize new database: \"+self.file)\n",
    "\n",
    "\n",
    "    def readPointIndicator(self):\n",
    "\n",
    "        self.PIList=[]\n",
    "        IDList = self.DB.attrs[\"IDList\"]\n",
    "        DimensionList = self.DB.attrs[\"IDDimensionList\"]\n",
    "        ToleranceList = self.DB.attrs[\"IDTolerance\"]\n",
    "\n",
    "        for i in range(0,len(IDList)):\n",
    "            self.PIList.append(PointIndicator(IDList[i],DimensionList[i],ToleranceList[i]))\n",
    "\n",
    "\n",
    "    def writePointIndicator(self):\n",
    "        IDList=[]\n",
    "        DimensionList=[]\n",
    "        ToleranceList=[]\n",
    "\n",
    "        for p_i in self.PIList:\n",
    "            IDList.append(p_i.AttributeName)\n",
    "            DimensionList.append(p_i.AttributeDimension)\n",
    "            ToleranceList.append(p_i.Tolerance)\n",
    "\n",
    "        self.DB.attrs[\"IDList\"] = IDList\n",
    "        self.DB.attrs[\"IDDimensionList\"] = DimensionList\n",
    "        self.DB.attrs[\"IDTolerance\"] = ToleranceList\n",
    "\n",
    "\n",
    "    def getPointIndicator(self):\n",
    "        return self.PIList\n",
    "\n",
    "    def getPoint(self,someVal):\n",
    "        if type(someVal) is Point:\n",
    "            point=self.getPointByPoint(someVal)\n",
    "        elif type(someVal) is h5py._hl.group.Group:\n",
    "            point=someVal\n",
    "        elif type(someVal) is dict:\n",
    "            point=self.getPointByIndicatorValue(someVal)\n",
    "        elif type(someVal) is int or type(someVal) is np.int32 or type(someVal) is np.int64:\n",
    "            point=self.getPointByNumber(someVal)\n",
    "        else:\n",
    "            print(\"unknown value type: {0}\".format(type(someVal)))\n",
    "            point=-1\n",
    "        return point\n",
    "\n",
    "    def getPointByPoint(self,point):\n",
    "        for key in self.DB.keys():\n",
    "            if DATABASE_POINT in key:\n",
    "                if np.linalg.norm(self.DB[key].attrs[self.PI[DATABASE_NAME]]-point.Attributes[self.PI[DATABASE_NAME]])<self.PI[\"Tolerance\"]:\n",
    "                    return self.DB[key]\n",
    "        return -1\n",
    "\n",
    "    def getPointByIndicatorValue(self,value):\n",
    "        for key in self.DB.keys():\n",
    "            if DATABASE_POINT in key:\n",
    "                ispoint=True\n",
    "                for i in range(0,len(self.PIList)):\n",
    "                    try:\n",
    "                        AttributeName=self.PIList[i].AttributeName\n",
    "                        val=value[self.PIList[i].AttributeName.decode(encoding)]\n",
    "                        if type(val)==list:\n",
    "                            val=np.asarray(val)\n",
    "                        if type(val)==float:\n",
    "                            val=np.asarray([val])\n",
    "                        if type(val)==int:\n",
    "                            val=np.asarray([val])\n",
    "                        dbval=self.DB[key].attrs[AttributeName]\n",
    "                        tol=self.PIList[i].Tolerance\n",
    "                    except:\n",
    "                        ispoint=False\n",
    "                        break\n",
    "\n",
    "                    if self.PIList[i].shape!=val.shape:\n",
    "                        ispoint=False\n",
    "                        break\n",
    "\n",
    "                    if np.linalg.norm(dbval-val)>tol:\n",
    "                        ispoint=False\n",
    "                        break\n",
    "                if ispoint:\n",
    "                    return self.DB[key]\n",
    "\n",
    "        print(\"can't find point for : {0}\".format(value))\n",
    "        return -1\n",
    "\n",
    "    def getPointByNumber(self,Number):\n",
    "        for key in self.DB.keys():\n",
    "            if DATABASE_POINT in key:\n",
    "                if self.DB[key].attrs[DATABASE_NUMBER]==Number:\n",
    "                    return self.DB[key]\n",
    "        print(\"can't find point with Number {0}\".format(Number))\n",
    "        return -1\n",
    "\n",
    "    def getModel(self,DatabasePoint,someVal):\n",
    "        if type(someVal) is Model:\n",
    "            model=self.getModelByModel(DatabasePoint,someVal)\n",
    "        elif type(someVal) is int:\n",
    "            model=self.getModelByNumber(DatabasePoint,someVal)\n",
    "        elif type(someVal) is dict:\n",
    "            model=self.getModelByDict(DatabasePoint,someVal)\n",
    "        elif type(someVal) is h5py._hl.group.Group:\n",
    "            return someVal\n",
    "        else:\n",
    "            print(\"unknown value type: {0}\".format(type(someVal)))\n",
    "            model=-1\n",
    "        return model\n",
    "\n",
    "\n",
    "    def getModelByModel(self,DatabasePoint,Model):\n",
    "        for key in DatabasePoint.keys():\n",
    "            if DATABASE_MODEL in key:\n",
    "                DatabaseModel=DatabasePoint[key]\n",
    "                if self.compareModel(DatabaseModel,Model):\n",
    "                    return DatabaseModel\n",
    "        return -1\n",
    "\n",
    "    def getModelByDict(self,DatabasePoint,ModelDict):\n",
    "        for key in DatabasePoint.keys():\n",
    "            if DATABASE_MODEL in key:\n",
    "                DatabaseModel=DatabasePoint[key]\n",
    "                ismodel=True\n",
    "                for key,val in DatabaseModel.attrs.items():\n",
    "                    if key!=DATABASE_NUMBER:\n",
    "                        try:\n",
    "                            if DatabaseModel.attrs[key].decode(encoding)!=ModelDict[key]:\n",
    "                                ismodel=False\n",
    "                                break\n",
    "                        except:\n",
    "                            ismodel=False\n",
    "                            break\n",
    "                if ismodel:\n",
    "                    return DatabaseModel\n",
    "        print(\"can't find Model in point: {0} with Attrs {1}\".format(DatabasePoint,ModelDict))\n",
    "\n",
    "        return -1\n",
    "\n",
    "\n",
    "    def getModelByNumber(self,DatabasePoint,Number):\n",
    "        for key in DatabasePoint.keys():\n",
    "            if DATABASE_MODEL in key:\n",
    "                DatabaseModel=DatabasePoint[key]\n",
    "                if DatabaseModel.attrs[DATABASE_NUMBER]==Number:\n",
    "                    return DatabaseModel\n",
    "        print(\"can't find Model in point: {0} with Number {1}\".format(DatabasePoint,Number))\n",
    "        return -1\n",
    "\n",
    "    def getHighestNumber(self,obj,name):\n",
    "        Number=0\n",
    "        for key in obj.keys():\n",
    "            if name in key:\n",
    "                if obj[key].attrs[DATABASE_NUMBER]>Number:\n",
    "                    Number=obj[key].attrs[DATABASE_NUMBER]\n",
    "        return Number\n",
    "\n",
    "\n",
    "    def addPoint(self,point):\n",
    "        if not self.write:\n",
    "            raise ValueError(\"(addPoint): No write intent\")\n",
    "        DatabasePoint = self.getPoint(point)\n",
    "        if DatabasePoint == -1:\n",
    "            print('Add Point: {0} to database'.format(point))\n",
    "            PointNumber = self.getHighestNumber(self.DB,DATABASE_POINT)\n",
    "            DatabasePoint=self.DB.create_group('Point_'+str(PointNumber+1))\n",
    "            for i in range(0,len(self.PIList)):\n",
    "                try:\n",
    "                    val=point[self.PIList[i].AttributeName.decode(encoding)]\n",
    "                except:\n",
    "                    raise ValueError(\"point indicator mismatch\")\n",
    "                DatabasePoint.attrs[self.PIList[i].AttributeName]=val\n",
    "            DatabasePoint.attrs[DATABASE_NUMBER]=PointNumber+1\n",
    "            self.meshing()\n",
    "\n",
    "        return DatabasePoint\n",
    "\n",
    "    def compareModel(self,DatabaseModel,Model):\n",
    "\n",
    "        if len(DatabaseModel.attrs) == len(Model.Attributes)+1:\n",
    "            for key,val in DatabaseModel.attrs.items():\n",
    "                if key!=DATABASE_NUMBER:\n",
    "                    try:\n",
    "                        if DatabaseModel.attrs[key]!=Model.Attributes[key]:\n",
    "                            return False\n",
    "                    except:\n",
    "                        return False\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "    def addModel(self,DatabasePoint,model):\n",
    "        if not self.write:\n",
    "            raise ValueError(\"No write intent\")\n",
    "\n",
    "        DatabaseModel=self.getModel(DatabasePoint,model)\n",
    "\n",
    "        if DatabaseModel == -1:\n",
    "            print(\"Add model to Point : {0}\".format(DatabasePoint))\n",
    "            if not self.write:\n",
    "                raise ValueError(\"No write intent\")\n",
    "            DatabasePoint=self.getPoint(DatabasePoint)\n",
    "            ModelNumber = self.getHighestNumber(DatabasePoint,DATABASE_MODEL)\n",
    "            DatabaseModel=DatabasePoint.create_group('Model_'+str(ModelNumber+1))\n",
    "            if type(model) is Model:\n",
    "                for key,val in model.Attributes.items():\n",
    "                    DatabaseModel.attrs[key]=np.string_(val)\n",
    "            if type(model) is dict:\n",
    "                for key,val in model.items():\n",
    "                    DatabaseModel.attrs[key]=np.string_(val)\n",
    "\n",
    "            DatabaseModel.attrs[DATABASE_NUMBER]=ModelNumber+1\n",
    "            matrices = DatabaseModel.create_group(DATABASE_MODEL_MATRIX)\n",
    "            modes    = DatabaseModel.create_group(DATABASE_MODEL_PODMODES)\n",
    "            volfield = DatabaseModel.create_group(DATABASE_MODEL_VOLUMEFIELDS)\n",
    "        else:\n",
    "            del DatabaseModel[DATABASE_MODEL_MATRIX]\n",
    "            del DatabaseModel[DATABASE_MODEL_PODMODES]\n",
    "            del DatabaseModel[DATABASE_MODEL_VOLUMEFIELDS]\n",
    "\n",
    "            if type(model) is Model:\n",
    "                for key,val in model.Attributes.items():\n",
    "                    DatabaseModel.attrs[key]=np.string_(val)\n",
    "            if type(model) is dict:\n",
    "                for key,val in model.items():\n",
    "                    DatabaseModel.attrs[key]=np.string_(val)\n",
    "\n",
    "            matrices = DatabaseModel.create_group(DATABASE_MODEL_MATRIX)\n",
    "            modes    = DatabaseModel.create_group(DATABASE_MODEL_PODMODES)\n",
    "            volfield = DatabaseModel.create_group(DATABASE_MODEL_VOLUMEFIELDS)\n",
    "        return DatabaseModel\n",
    "\n",
    "\n",
    "    def updateModelData(self,pointVal,ModelVal,MatrixDict,PODMODE=False,VOLUMEFIELD=False):\n",
    "        point=self.getPoint(pointVal)\n",
    "        if point==-1:\n",
    "            return -1\n",
    "        model=self.getModel(point,ModelVal)\n",
    "        if model==-1:\n",
    "            if type(ModelVal) is Model:\n",
    "                self.addModel(point,ModelVal)\n",
    "            else:\n",
    "                print(\"can not add new model. Type {0} != Model {1}\".format(type(ModelVal), Model))\n",
    "                raise ValueError(\"can not add new model\")\n",
    "                return -1\n",
    "        if not self.write:\n",
    "            raise ValueError(\"No write intent\")\n",
    "\n",
    "        if not PODMODE and not VOLUMEFIELD:\n",
    "            matrices = model[DATABASE_MODEL_MATRIX]\n",
    "            ListOfNames= self.ListOfMatrixNames(model)\n",
    "            it = len(matrices)+1\n",
    "            for key,val in MatrixDict.items():\n",
    "                ListOfNames= self.ListOfMatrixNames(model)\n",
    "                if key in ListOfNames:\n",
    "                    dataset=self.getMatrixByName(model,key)\n",
    "                    dataset.resize(np.array(val).shape)\n",
    "                    dataset[...]=val\n",
    "                else:\n",
    "                    array = np.array(val)\n",
    "                    currentShape = array.shape\n",
    "                    dimension = len(currentShape)\n",
    "                    noneList = []                      \n",
    "                    for i in range(0,dimension):\n",
    "                        noneList.append(None)\n",
    "                    if self.compression:                        \n",
    "                        dataset=matrices.create_dataset('SystemMatrix_'+str(it), data=val, compression='gzip',maxshape=tuple(noneList))\n",
    "                    else: \n",
    "                        dataset=matrices.create_dataset('SystemMatrix_'+str(it), data=val,maxshape=tuple(noneList))\n",
    "                    dataset.attrs[DATABASE_NUMBER] = it\n",
    "                    dataset.attrs[DATABASE_NAME]   = np.string_(key)\n",
    "                    it+=1\n",
    "            return model\n",
    "        elif PODMODE and not VOLUMEFIELD:\n",
    "            try:\n",
    "                modes = model[DATABASE_MODEL_PODMODES]\n",
    "            except:\n",
    "                modes = model.create_group(DATABASE_MODEL_PODMODES)\n",
    "            ListOfNames= self.ListOfModeNames(model)\n",
    "            it = len(modes)+1\n",
    "            for key,val in MatrixDict.items():\n",
    "                ListOfNames= self.ListOfModeNames(model)\n",
    "                if key in ListOfNames:\n",
    "                    dataset=self.getModeByName(model,key)\n",
    "                    dataset[...]=val.transpose()\n",
    "                else:\n",
    "                    if self.compression:\n",
    "                      dataset=modes.create_dataset('Mode_'+str(it), data=val.transpose(), compression='gzip')\n",
    "                    else:\n",
    "                      dataset=modes.create_dataset('Mode_'+str(it), data=val.transpose(), chunks=True)\n",
    "                    dataset.attrs[DATABASE_NUMBER] = it\n",
    "                    dataset.attrs[DATABASE_NAME]   = np.string_(key)\n",
    "                    it+=1\n",
    "            return model\n",
    "        elif VOLUMEFIELD and not PODMODE:\n",
    "            try:\n",
    "                modes = model[DATABASE_MODEL_VOLUMEFIELDS]\n",
    "            except:\n",
    "                modes = model.create_group(DATABASE_MODEL_VOLUMEFIELDS)\n",
    "            ListOfNames= self.ListOfVolumeFieldNames(model)\n",
    "            it = len(modes)+1\n",
    "            for key,val in MatrixDict.items():\n",
    "                ListOfNames= self.ListOfVolumeFieldNames(model)\n",
    "                if key in ListOfNames:\n",
    "                    dataset=self.getVolumeFieldByName(model,key)\n",
    "                    dataset[...]=val.transpose()\n",
    "                else:\n",
    "                    if self.compression:\n",
    "                      dataset=modes.create_dataset('VolumeField_'+str(it),data=val.transpose(), compression='gzip')\n",
    "                    else:\n",
    "                      dataset=modes.create_dataset('VolumeField_'+str(it),data=val.transpose())\n",
    "                    dataset.attrs[DATABASE_NUMBER] = it\n",
    "                    dataset.attrs[DATABASE_NAME]   = np.string_(key)\n",
    "                    it+=1\n",
    "                it+=1\n",
    "            return model\n",
    "        else:\n",
    "            raise ValueError('(updateModelData): unclassified Type of Data')\n",
    "\n",
    "\n",
    "\n",
    "    def extendModelData(self,pointVal,ModelVal,MatrixDict,PODMODE=False,VOLUMEFIELD=False):\n",
    "        point=self.getPoint(pointVal)\n",
    "        if point==-1:\n",
    "            return -1\n",
    "        model=self.getModel(point,ModelVal)\n",
    "        if model==-1:\n",
    "            if type(ModelVal) is Model:\n",
    "                self.addModel(point,ModelVal)\n",
    "            else:\n",
    "                print(\"can not add new model. Type {0} != Model\".format(type(ModelVal)))\n",
    "                raise ValueError(\"can not add new model\")\n",
    "                return -1\n",
    "        if not self.write:\n",
    "            raise ValueError(\"No write intent\")\n",
    "\n",
    "        if not PODMODE and not VOLUMEFIELD:\n",
    "            matrices = model[DATABASE_MODEL_MATRIX]\n",
    "            ListOfNames= self.ListOfMatrixNames(model)\n",
    "            for key in MatrixDict.keys():\n",
    "                if key in ListOfNames:\n",
    "                    print(\"Unable to create link (Name already exists)\")\n",
    "                    raise ValueError(\"Matrix name: \"+ key +\" already exists\" )\n",
    "                    return -1\n",
    "            it = len(matrices)+1\n",
    "            for key,val in MatrixDict.items():\n",
    "                ListOfNames= self.ListOfMatrixNames(model)\n",
    "                if key in ListOfNames:\n",
    "                    print(\"Unable to create link (Name already exists)\")\n",
    "                    raise ValueError(\"Matrix name: \"+ key +\" already exists\" )\n",
    "                    return -1\n",
    "                if self.compression:\n",
    "                  dataset=matrices.create_dataset('SystemMatrix_'+str(it), data=val, compression='gzip')\n",
    "                else:\n",
    "                  dataset=matrices.create_dataset('SystemMatrix_'+str(it), data=val, chunks=True)\n",
    "                dataset.attrs[DATABASE_NUMBER] = it\n",
    "                dataset.attrs[DATABASE_NAME]   = np.string_(key)\n",
    "                it+=1\n",
    "            return model\n",
    "\n",
    "        elif PODMODE and not VOLUMEFIELD:\n",
    "            try:\n",
    "                modes = model[DATABASE_MODEL_PODMODES]\n",
    "            except:\n",
    "                modes = model.create_group(DATABASE_MODEL_PODMODES)\n",
    "            ListOfNames= self.ListOfModeNames(model)\n",
    "            for key in MatrixDict.keys():\n",
    "                if key in ListOfNames:\n",
    "                    print(\"Unable to create link (Name already exists)\")\n",
    "                    raise ValueError(\"Mode name: \"+ key +\" already exists\" )\n",
    "                    return -1\n",
    "            it = len(modes)+1\n",
    "            for key,val in MatrixDict.items():\n",
    "                ListOfNames= self.ListOfModeNames(model)\n",
    "                if key in ListOfNames:\n",
    "                    print(\"Unable to create link (Name already exists)\")\n",
    "                    raise ValueError(\"Matrix name: \"+ key +\" already exists\" )\n",
    "                    return -1\n",
    "                if self.compression:\n",
    "                  dataset=modes.create_dataset('Mode_'+str(it), data=val.transpose(), compression='gzip')\n",
    "                else:\n",
    "                  dataset=modes.create_dataset('Mode_'+str(it), data=val.transpose())\n",
    "                dataset.attrs[DATABASE_NUMBER] = it\n",
    "                dataset.attrs[DATABASE_NAME]   = np.string_(key)\n",
    "                it+=1\n",
    "            return model\n",
    "        elif VOLUMEFIELD and not PODMODE:\n",
    "            try:\n",
    "                modes = model[DATABASE_MODEL_VOLUMEFIELDS]\n",
    "            except:\n",
    "                modes = model.create_group(DATABASE_MODEL_VOLUMEFIELDS)\n",
    "            ListOfNames= self.ListOfVolumeFieldNames(model)\n",
    "\n",
    "            for key in MatrixDict.keys():\n",
    "                if key in ListOfNames:\n",
    "                    print(\"Unable to create link (Name already exists)\")\n",
    "                    raise ValueError(\"Mode name: \"+ key +\" already exists\" )\n",
    "                    return -1\n",
    "            it = len(modes)+1\n",
    "            for key,val in MatrixDict.items():\n",
    "                ListOfNames= self.ListOfVolumeFieldNames(model)\n",
    "                if key in ListOfNames:\n",
    "                    print(\"Unable to create link (Name already exists)\")\n",
    "                    raise ValueError(\"Matrix name: \"+ key +\" already exists\" )\n",
    "                    return -1\n",
    "                if self.compression:\n",
    "                  dataset=modes.create_dataset('VolumeField_'+str(it), data=val.transpose(), compression='gzip')\n",
    "                else:\n",
    "                  dataset=modes.create_dataset('VolumeField_'+str(it), data=val.transpose())\n",
    "                dataset.attrs[DATABASE_NUMBER] = it\n",
    "                dataset.attrs[DATABASE_NAME]   = np.string_(key)\n",
    "                it+=1\n",
    "            return model\n",
    "        else:\n",
    "            raise ValueError('(extendModelData): unclassified Type of Data')\n",
    "\n",
    "\n",
    "\n",
    "    def ListOfMatrixNames(self,model):\n",
    "        matrices = model[DATABASE_MODEL_MATRIX]\n",
    "        NameList=[]\n",
    "        for key in matrices.keys():\n",
    "            NameList.append(model[DATABASE_MODEL_MATRIX][key].attrs[DATABASE_NAME])\n",
    "        return NameList\n",
    "\n",
    "    def getMatrixByName(self,model,name):\n",
    "        matrices = model[DATABASE_MODEL_MATRIX]\n",
    "        for key in matrices.keys():\n",
    "            if model[DATABASE_MODEL_MATRIX][key].attrs[DATABASE_NAME]== name:\n",
    "                return model[DATABASE_MODEL_MATRIX][key]\n",
    "        return -1\n",
    "\n",
    "    def getModeByName(self,model,name):\n",
    "        matrices = model[DATABASE_MODEL_PODMODES]\n",
    "        for key in matrices.keys():\n",
    "            if model[DATABASE_MODEL_PODMODES][key].attrs[DATABASE_NAME]== name:\n",
    "                return model[DATABASE_MODEL_PODMODES][key]\n",
    "        return -1\n",
    "\n",
    "    def ListOfModeNames(self,model):\n",
    "        modes = model[DATABASE_MODEL_PODMODES]\n",
    "        NameList=[]\n",
    "        for key in modes.keys():\n",
    "            NameList.append(model[DATABASE_MODEL_PODMODES][key].attrs[DATABASE_NAME])\n",
    "        return NameList\n",
    "\n",
    "    def getVolumeFieldByName(self,model,name):\n",
    "        matrices = model[DATABASE_MODEL_VOLUMEFIELDS]\n",
    "        for key in matrices.keys():\n",
    "            if model[DATABASE_MODEL_VOLUMEFIELDS][key].attrs[DATABASE_NAME]== name:\n",
    "                return model[DATABASE_MODEL_VOLUMEFIELDS][key]\n",
    "        return -1\n",
    "\n",
    "    def ListOfVolumeFieldNames(self,model):\n",
    "        modes = model[DATABASE_MODEL_VOLUMEFIELDS]\n",
    "        NameList=[]\n",
    "        for key in modes.keys():\n",
    "            NameList.append(model[DATABASE_MODEL_VOLUMEFIELDS][key].attrs[DATABASE_NAME])\n",
    "        return NameList\n",
    "\n",
    "\n",
    "    def getData(self,TYPE,pointVal,ModelVal,name=None):\n",
    "        point=self.getPoint(pointVal)\n",
    "        if point==-1:\n",
    "            return -1\n",
    "        model=self.getModel(point,ModelVal)\n",
    "        if model==-1:\n",
    "            return -1\n",
    "        if type(name)!=str:\n",
    "            if TYPE==DATABASE_MODEL_MATRIX:\n",
    "                data=self.getSystemMatrices(model)\n",
    "            elif TYPE==DATABASE_MODEL_PODMODES:\n",
    "                data=self.getModes(model)\n",
    "            elif TYPE==DATABASE_MODEL_VOLUMEFIELDS:\n",
    "                data=self.getVolumeFields(model)\n",
    "        else:\n",
    "            if TYPE==DATABASE_MODEL_MATRIX:\n",
    "                data=self.getSystemMatrix(model,name)\n",
    "            elif TYPE==DATABASE_MODEL_PODMODES:\n",
    "                data=self.getMode(model,name)\n",
    "            elif TYPE==DATABASE_MODEL_VOLUMEFIELDS:\n",
    "                data=self.getVolumeField(model,name)\n",
    "        return data\n",
    "\n",
    "    def getInternName(self,TYPE,pointVal,ModelVal,name):\n",
    "        point=self.getPoint(pointVal)\n",
    "        if point==-1:\n",
    "            return -1\n",
    "        model=self.getModel(point,ModelVal)\n",
    "        if model==-1:\n",
    "            return -1\n",
    "\n",
    "        if TYPE==DATABASE_MODEL_MATRIX:\n",
    "            for key in model[DATABASE_MODEL_MATRIX].keys():\n",
    "                if model[DATABASE_MODEL_MATRIX][key].attrs[DATABASE_NAME]==name:\n",
    "                    return key\n",
    "        elif TYPE==DATABASE_MODEL_PODMODES:\n",
    "            for key in model[DATABASE_MODEL_PODMODES].keys():\n",
    "                if model[DATABASE_MODEL_PODMODES][key].attrs[DATABASE_NAME]==name:\n",
    "                    return key\n",
    "        elif TYPE==DATABASE_MODEL_VOLUMEFIELDS:\n",
    "            for key in model[DATABASE_MODEL_VOLUMEFIELDS].keys():\n",
    "                if model[DATABASE_MODEL_VOLUMEFIELDS][key].attrs[DATABASE_NAME]==name:\n",
    "                    return key\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "\n",
    "    def getSystemMatrices(self,DatabaseModel):\n",
    "        ret={}\n",
    "        for key in DatabaseModel[DATABASE_MODEL_MATRIX].keys():\n",
    "            ret[DatabaseModel[DATABASE_MODEL_MATRIX][key].attrs[DATABASE_NAME]]=DatabaseModel[DATABASE_MODEL_MATRIX][key][...]\n",
    "        return ret\n",
    "\n",
    "    def getSystemMatrix(self,DatabaseModel,name):\n",
    "        print(DatabaseModel[DATABASE_MODEL_MATRIX])\n",
    "        for key in DatabaseModel[DATABASE_MODEL_MATRIX].keys():\n",
    "            if DatabaseModel[DATABASE_MODEL_MATRIX][key].attrs[DATABASE_NAME]==name:\n",
    "                return DatabaseModel[DATABASE_MODEL_MATRIX][key][...]\n",
    "        print(\"Dataset: {0} can't be found in Model\".format(name))\n",
    "        return -1\n",
    "\n",
    "    def getModes(self,DatabaseModel):\n",
    "        ret={}\n",
    "        for key in DatabaseModel[DATABASE_MODEL_PODMODES].keys():\n",
    "            ret[DatabaseModel[DATABASE_MODEL_PODMODES][key].attrs[DATABASE_NAME]]=DatabaseModel[DATABASE_MODEL_PODMODES][key][...].transpose()\n",
    "        return ret\n",
    "\n",
    "    def getNumberOfModes(self,DatabaseModel):\n",
    "        return len(DatabaseModel[DATABASE_MODEL_PODMODES].keys())\n",
    "\n",
    "    def getMode(self,DatabaseModel,name):\n",
    "        for key in DatabaseModel[DATABASE_MODEL_PODMODES].keys():\n",
    "\n",
    "            if DatabaseModel[DATABASE_MODEL_PODMODES][key].attrs[DATABASE_NAME]==name:\n",
    "                return DatabaseModel[DATABASE_MODEL_PODMODES][key][...].transpose()\n",
    "        print(\"Dataset: {0} can't be found in Model\".format(name))\n",
    "        return -1\n",
    "\n",
    "    def getVolumeFields(self,DatabaseModel):\n",
    "        ret={}\n",
    "        for key in DatabaseModel[DATABASE_MODEL_VOLUMEFIELDS].keys():\n",
    "            ret[DatabaseModel[DATABASE_MODEL_VOLUMEFIELDS][key].attrs[DATABASE_NAME]]=DatabaseModel[DATABASE_MODEL_VOLUMEFIELDS][key][...].transpose()\n",
    "        return ret\n",
    "\n",
    "    def getVolumeField(self,DatabaseModel,name):\n",
    "        for key in DatabaseModel[DATABASE_MODEL_VOLUMEFIELDS].keys():\n",
    "\n",
    "            if DatabaseModel[DATABASE_MODEL_VOLUMEFIELDS][key].attrs[DATABASE_NAME]==name:\n",
    "                return DatabaseModel[DATABASE_MODEL_VOLUMEFIELDS][key][...].transpose()\n",
    "        print(\"Dataset: {0} can't be found in Model\".format(name))\n",
    "        return -1\n",
    "\n",
    "\n",
    "    def meshing(self):\n",
    "        try:\n",
    "            FOdim = self.PIList[0].AttributeDimension\n",
    "            if FOdim==2:\n",
    "                self.meshingFiberOrientation()\n",
    "            else:\n",
    "                print('no mesh generation implemented for indicator {0}.'.format(self.PIList[0].AttributeName))\n",
    "        except:\n",
    "            print('no mesh generation implemented for indicator {0}.'.format(self.PIList[0].AttributeName))\n",
    "\n",
    "\n",
    "\n",
    "    def meshingFiberOrientation(self):\n",
    "\n",
    "        def checkArea(mtri):\n",
    "            nTS=[]\n",
    "            for T in mtri.triangles:\n",
    "                A=np.ones((3,3))\n",
    "                cnt=0\n",
    "                for i in T:\n",
    "                    A[cnt,1]=mtri.x[T[cnt]]\n",
    "                    A[cnt,2]=mtri.y[T[cnt]]\n",
    "                    cnt=cnt+1\n",
    "                    F=0.5*np.linalg.det(A)\n",
    "                    if F>1e-10:\n",
    "                        nTS.append(T)\n",
    "                        break\n",
    "            mtri.triangles=np.array(nTS)\n",
    "\n",
    "        mySimplice =[]\n",
    "        if(self.getHighestNumber(self.DB,DATABASE_POINT)>=3):\n",
    "            points=[]\n",
    "            pointNumbers=[]\n",
    "            pointTemperatures=[]\n",
    "            for p in range(1,self.getHighestNumber(self.DB,DATABASE_POINT)+1):\n",
    "                point=self.getPoint(p)\n",
    "                pointNumbers.append(point.attrs[DATABASE_NUMBER])\n",
    "                points.append(point.attrs[self.PIList[0].AttributeName])\n",
    "                pointTemperatures.append(point.attrs[self.PIList[1].AttributeName])\n",
    "                                    \n",
    "            for d in set(pointTemperatures):\n",
    "                points_d = []\n",
    "                pointNumbers_d = []\n",
    "                for p in range(len(points)):\n",
    "                    if d == pointTemperatures[p]:\n",
    "                        points_d.append(points[p])\n",
    "                        pointNumbers_d.append(pointNumbers[p])\n",
    "                \n",
    "                if len(points_d) < 3:\n",
    "                    continue\n",
    "                \n",
    "                nts=np.array(points_d)\n",
    "                checkONEline = True  \n",
    "                cnt = 2                \n",
    "                px  = points_d[0][0]\n",
    "                py  = points_d[0][1]\n",
    "                qx  = points_d[1][0]\n",
    "                qy  = points_d[1][1]\n",
    "\n",
    "                dpqx = px - qx\n",
    "                dpqy = py - qy\n",
    "                while(checkONEline and cnt<len(points_d)):\n",
    "                    mpx = points_d[cnt][0]\n",
    "                    mpy = points_d[cnt][1]\n",
    "                    dpmx = px - mpx\n",
    "                    dpmy = py - mpy\n",
    "                    cross = dpqx * dpmy - dpqy * dpmx\n",
    "                    if(np.abs(cross)>1e-4):\n",
    "                        checkONEline= False\n",
    "                    cnt=cnt+1\n",
    "                if(not checkONEline):\n",
    "                    mtri=tri.Triangulation(nts[:,0],nts[:,1])\n",
    "                    checkArea(mtri)\n",
    "                    for s in mtri.triangles:\n",
    "                        myS =[]\n",
    "                        for pN in s:\n",
    "                            myS.append(pointNumbers_d[pN])\n",
    "                        mySimplice.append(copy.deepcopy(myS))\n",
    "        try:\n",
    "            self.DB[DATABASE_MESH]\n",
    "        except:\n",
    "            self.MeshIsAvailable =False\n",
    "\n",
    "        if(self.MeshIsAvailable):\n",
    "            del self.DB[DATABASE_MESH]\n",
    "        if len(mySimplice)==0:\n",
    "            mySimplice=[[-1,-1,-1]]\n",
    "        meshgroup = self.DB.create_group(DATABASE_MESH)\n",
    "        dataset= meshgroup.create_dataset(DATABASE_CONNECTIVITY, data=np.asarray(mySimplice))\n",
    "\n",
    "    def getMesh(self):\n",
    "        try:\n",
    "            self.DB[DATABASE_MESH]\n",
    "            self.MeshIsAvailable =True\n",
    "        except:\n",
    "            self.MeshIsAvailable =False\n",
    "        if(self.MeshIsAvailable):\n",
    "            return self.DB[DATABASE_MESH][DATABASE_CONNECTIVITY][...]\n",
    "        else:\n",
    "            print(\"Mesh can not be found\")\n",
    "            return -1\n",
    "\n",
    "    def writeXDMF(self):\n",
    "        itdim=0\n",
    "        root = ET.Element('Xdmf')\n",
    "        root.set('Version','2.2')\n",
    "\n",
    "        domain=ET.SubElement(root,'Domain')\n",
    "\n",
    "        grid=ET.SubElement(domain,'Grid')\n",
    "        grid.set('GridType','Uniform')\n",
    "        grid.set('Collection',str(itdim))\n",
    "\n",
    "        Topology=ET.SubElement(grid,'Topology')\n",
    "        Topology.set('TopologyType','3DCORECTMesh')\n",
    "\n",
    "        geometry=ET.SubElement(grid,\"Geometry\")\n",
    "        geometry.set('GeometryType','ORIGIN_DXDYDZ')\n",
    "\n",
    "        DataItemOrigin=ET.SubElement(geometry,'DataItem')\n",
    "        DataItemOrigin.set('Name','Origin')\n",
    "        DataItemOrigin.set('Dimensions','3')\n",
    "        DataItemOrigin.set('NumberType','Float')\n",
    "        DataItemOrigin.set('Precision','4')\n",
    "        DataItemOrigin.set('Format','XML')\n",
    "        DataItemOrigin.text='0 0 0'\n",
    "\n",
    "        DataItemSpacing=ET.SubElement(geometry,'DataItem')\n",
    "        DataItemSpacing.set('Name','Spacing')\n",
    "        DataItemSpacing.set('Dimensions','3')\n",
    "        DataItemSpacing.set('NumberType','Float')\n",
    "        DataItemSpacing.set('Precision','4')\n",
    "        DataItemSpacing.set('Format','XML')\n",
    "        DataItemSpacing.text='1 1 1'\n",
    "\n",
    "\n",
    "        NumberOfPoints = self.getHighestNumber(self.DB,DATABASE_POINT)\n",
    "        dims=[]\n",
    "\n",
    "        for i in range(1,NumberOfPoints+1):\n",
    "            point=self.getPoint(i)\n",
    "            NumberOfModels = self.getHighestNumber(point,DATABASE_MODEL)\n",
    "            for j in range(1,NumberOfModels+1):\n",
    "                model=self.getModel(point,j)\n",
    "                modes=self.getData(DATABASE_MODEL_VOLUMEFIELDS,i,j)\n",
    "                it=0\n",
    "                for key,val in modes.items():\n",
    "\n",
    "                    it+=1\n",
    "                    if len(val.shape)==4:\n",
    "                        dimsNew=[val.shape[3],val.shape[2],val.shape[1]]\n",
    "                    if len(val.shape)==3:\n",
    "                        dimsNew=[val.shape[2],val.shape[1],val.shape[0]]\n",
    "\n",
    "                    if len(dims)>0:\n",
    "                        if dims !=dimsNew:\n",
    "                            itdim+=1\n",
    "                            grid=ET.SubElement(domain,'Grid')\n",
    "                            grid.set('GridType','Uniform')\n",
    "                            grid.set('Collection',str(itdim))\n",
    "\n",
    "                            Topology=ET.SubElement(grid,'Topology')\n",
    "                            Topology.set('TopologyType','3DCORECTMesh')\n",
    "                            Topology.set('Dimensions',str(dimsNew[0]+1)+' '+str(dimsNew[1]+1)+' '+str(dimsNew[2]+1))\n",
    "\n",
    "                            geometry=ET.SubElement(grid,\"Geometry\")\n",
    "                            geometry.set('GeometryType','ORIGIN_DXDYDZ')\n",
    "\n",
    "                            DataItemOrigin=ET.SubElement(geometry,'DataItem')\n",
    "                            DataItemOrigin.set('Name','Origin')\n",
    "                            DataItemOrigin.set('Dimensions','3')\n",
    "                            DataItemOrigin.set('NumberType','Float')\n",
    "                            DataItemOrigin.set('Precision','4')\n",
    "                            DataItemOrigin.set('Format','XML')\n",
    "                            DataItemOrigin.text='0 0 0'\n",
    "\n",
    "                            DataItemSpacing=ET.SubElement(geometry,'DataItem')\n",
    "                            DataItemSpacing.set('Name','Spacing')\n",
    "                            DataItemSpacing.set('Dimensions','3')\n",
    "                            DataItemSpacing.set('NumberType','Float')\n",
    "                            DataItemSpacing.set('Precision','4')\n",
    "                            DataItemSpacing.set('Format','XML')\n",
    "                            DataItemSpacing.text='1 1 1'\n",
    "                    else:\n",
    "                        Topology.set('Dimensions',str(dimsNew[0]+1)+' '+str(dimsNew[1]+1)+' '+str(dimsNew[2]+1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    #Namestring='Point_'+str(i)+'/'+model.attrs[DATABASE_MODELTYPE]+'/'+key\n",
    "                    Namestring='Point_'+str(i)+'/'\n",
    "                    for attrKeys in model.attrs.keys():\n",
    "                      if attrKeys != DATABASE_NUMBER:\n",
    "                        Namestring += attrKeys + '_' + str(model.attrs[attrKeys])+'/'\n",
    "                    Namestring += key\n",
    "\n",
    "                    Attribute=ET.SubElement(grid,'Attribute')\n",
    "                    Attribute.set('Name',Namestring)\n",
    "                    Attribute.set('Center','Cell')\n",
    "                    DataItem=ET.SubElement(Attribute,'DataItem')\n",
    "                    if len(val.shape)==3:\n",
    "                        Attribute.set('AttributeType','Scalar')\n",
    "                        DataItem.set('Dimensions',str(val.shape[2])+' '+str(val.shape[1])+' '+str(val.shape[0]))\n",
    "                    elif val.shape[0]==1:\n",
    "                        Attribute.set('AttributeType','Scalar')\n",
    "                        DataItem.set('Dimensions',str(val.shape[3])+' '+str(val.shape[2])+' '+str(val.shape[1]))\n",
    "                    elif val.shape[0]==3:\n",
    "                        Attribute.set('AttributeType','Vector')\n",
    "                        DataItem.set('Dimensions',str(val.shape[3])+' '+str(val.shape[2])+' '+str(val.shape[1])+' '+str(val.shape[0]))\n",
    "                    elif val.shape[0]==6:\n",
    "                        Attribute.set('AttributeType','Tensor6')\n",
    "                        DataItem.set('Dimensions',str(val.shape[3])+' '+str(val.shape[2])+' '+str(val.shape[1])+' '+str(val.shape[0]))\n",
    "                    elif val.shape[0]==9:\n",
    "                        Attribute.set('AttributeType','Tensor')\n",
    "                        DataItem.set('Dimensions',str(val.shape[3])+' '+str(val.shape[2])+' '+str(val.shape[1])+' '+str(val.shape[0]))\n",
    "                    else:\n",
    "                        raise ValueError('unexpected mode shape')\n",
    "                    DataItem.set('NumberType','Float')\n",
    "                    DataItem.set('Format','HDF')\n",
    "                    DataItem.text=os.path.basename(self.file)+':/Point_'+str(i)+'/Model_'+str(j)+'/'+DATABASE_MODEL_VOLUMEFIELDS+'/'+self.getInternName(DATABASE_MODEL_VOLUMEFIELDS,point,model,key)\n",
    "                    dims =dimsNew\n",
    "\n",
    "                modes=self.getData(DATABASE_MODEL_PODMODES,i,j)\n",
    "                it=0\n",
    "                for key,val in modes.items():\n",
    "\n",
    "                    it+=1\n",
    "                    if len(val.shape)==4:\n",
    "                        dimsNew=[val.shape[3],val.shape[2],val.shape[1]]\n",
    "                    if len(val.shape)==3:\n",
    "                        dimsNew=[val.shape[2],val.shape[1],val.shape[0]]\n",
    "\n",
    "                    if len(dims)>0:\n",
    "                        if dims !=dimsNew:\n",
    "                            itdim+=1\n",
    "                            grid=ET.SubElement(domain,'Grid')\n",
    "                            grid.set('GridType','Uniform')\n",
    "                            grid.set('Collection',str(itdim))\n",
    "\n",
    "                            Topology=ET.SubElement(grid,'Topology')\n",
    "                            Topology.set('TopologyType','3DCORECTMesh')\n",
    "                            Topology.set('Dimensions',str(dimsNew[0]+1)+' '+str(dimsNew[1]+1)+' '+str(dimsNew[2]+1))\n",
    "\n",
    "                            geometry=ET.SubElement(grid,\"Geometry\")\n",
    "                            geometry.set('GeometryType','ORIGIN_DXDYDZ')\n",
    "\n",
    "                            DataItemOrigin=ET.SubElement(geometry,'DataItem')\n",
    "                            DataItemOrigin.set('Name','Origin')\n",
    "                            DataItemOrigin.set('Dimensions','3')\n",
    "                            DataItemOrigin.set('NumberType','Float')\n",
    "                            DataItemOrigin.set('Precision','4')\n",
    "                            DataItemOrigin.set('Format','XML')\n",
    "                            DataItemOrigin.text='0 0 0'\n",
    "\n",
    "                            DataItemSpacing=ET.SubElement(geometry,'DataItem')\n",
    "                            DataItemSpacing.set('Name','Spacing')\n",
    "                            DataItemSpacing.set('Dimensions','3')\n",
    "                            DataItemSpacing.set('NumberType','Float')\n",
    "                            DataItemSpacing.set('Precision','4')\n",
    "                            DataItemSpacing.set('Format','XML')\n",
    "                            DataItemSpacing.text='1 1 1'\n",
    "                    else:\n",
    "                        Topology.set('Dimensions',str(dimsNew[0]+1)+' '+str(dimsNew[1]+1)+' '+str(dimsNew[2]+1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    #Namestring='Point_'+str(i)+'/'+model.attrs[DATABASE_MODELTYPE]+'/'+key\n",
    "                    Namestring='Point_'+str(i)+'/'\n",
    "                    for attrKeys in model.attrs.keys():\n",
    "                      if attrKeys != DATABASE_NUMBER:\n",
    "                        Namestring += attrKeys + '_' + str(model.attrs[attrKeys])+'/'\n",
    "                    Namestring += key\n",
    "\n",
    "                    Attribute=ET.SubElement(grid,'Attribute')\n",
    "                    Attribute.set('Name',Namestring)\n",
    "                    Attribute.set('Center','Cell')\n",
    "                    DataItem=ET.SubElement(Attribute,'DataItem')\n",
    "                    if len(val.shape)==3:\n",
    "                        Attribute.set('AttributeType','Scalar')\n",
    "                        DataItem.set('Dimensions',str(val.shape[2])+' '+str(val.shape[1])+' '+str(val.shape[0]))\n",
    "                    elif val.shape[0]==1:\n",
    "                        Attribute.set('AttributeType','Scalar')\n",
    "                        DataItem.set('Dimensions',str(val.shape[3])+' '+str(val.shape[2])+' '+str(val.shape[1]))\n",
    "                    elif val.shape[0]==3:\n",
    "                        Attribute.set('AttributeType','Vector')\n",
    "                        DataItem.set('Dimensions',str(val.shape[3])+' '+str(val.shape[2])+' '+str(val.shape[1])+' '+str(val.shape[0]))\n",
    "                    elif val.shape[0]==6:\n",
    "                        Attribute.set('AttributeType','Tensor6')\n",
    "                        DataItem.set('Dimensions',str(val.shape[3])+' '+str(val.shape[2])+' '+str(val.shape[1])+' '+str(val.shape[0]))\n",
    "                    elif val.shape[0]==9:\n",
    "                        Attribute.set('AttributeType','Tensor')\n",
    "                        DataItem.set('Dimensions',str(val.shape[3])+' '+str(val.shape[2])+' '+str(val.shape[1])+' '+str(val.shape[0]))\n",
    "                    else:\n",
    "                        print(val.shape)\n",
    "                        raise ValueError('unexpected mode shape')\n",
    "                    DataItem.set('NumberType','Float')\n",
    "                    DataItem.set('Format','HDF')\n",
    "                    DataItem.text=os.path.basename(self.file)+':/Point_'+str(i)+'/Model_'+str(j)+'/'+DATABASE_MODEL_PODMODES+'/'+self.getInternName(DATABASE_MODEL_PODMODES,point,model,key)\n",
    "                    dims =dimsNew\n",
    "\n",
    "\n",
    "        indent(root)\n",
    "        tree = ET.ElementTree(root)\n",
    "        tree.write(self.file + \".xdmf\", encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce0513f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
